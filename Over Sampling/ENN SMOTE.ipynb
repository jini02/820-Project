{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afda223-1bb8-4c79-808d-5356062bb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "# pd.set_option(\"display.max_rows\",None)\n",
    "from scipy.stats import shapiro,mannwhitneyu,chi2_contingency\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from IPython.display import Image\n",
    "# from sklearn.tree import export_graphviz\n",
    "import imblearn\n",
    "\n",
    "\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4da4dc-6d6d-4a58-b244-dda1e9260a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf73826-32bc-4ac9-95c9-9b95a7fb17cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/nabee/Desktop/CIND 820/dffinal.csv')\n",
    "dfwork = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0287c8d1-395b-47f3-892d-e1e706f9e924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x:  (12330, 51)\n",
      "Shape of y:  (12330,)\n",
      "Shape of x_train : (9864, 51)\n",
      "Shape of y_train : (9864,)\n",
      "Shape of x_test : (2466, 51)\n",
      "Shape of y_test : (2466,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting Train and Test Data Set\n",
    "y = dfwork['Revenue']\n",
    "x = dfwork.drop(['Revenue'], axis = 1)\n",
    "\n",
    "# checking the shapes\n",
    "print(\"Shape of x: \", x.shape)\n",
    "print(\"Shape of y: \", y.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =  0.2, random_state = 0)\n",
    "\n",
    "print(\"Shape of x_train :\", x_train.shape)\n",
    "print(\"Shape of y_train :\", y_train.shape)\n",
    "print(\"Shape of x_test :\", x_test.shape)\n",
    "print(\"Shape of y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57642e3-8413-44a5-bd3c-4340dcf71428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min Max Scaler \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()    \n",
    "scaler.fit(x_train)       \n",
    "x_train = scaler.transform(x_train)    \n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbfaff2-7bfc-49a4-8a2c-3536e5befcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418ff3e0-3012-4e57-bd19-57cc29903f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f32a7b-551b-4952-a446-e552b959642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (14332, 51)\n",
      "After OverSampling, the shape of train_y: (14332,) \n",
      "\n",
      "After OverSampling, counts of label '1': 7571\n",
      "After OverSampling, counts of label '0': 6761\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "s_enn = SMOTEENN(random_state=42,sampling_strategy = 'auto')\n",
    "x_train, y_train = s_enn.fit_resample(x_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(x_train.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc49189-7816-4bc0-b595-8f3f478f588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "LR = LogisticRegression().fit(x_train, y_train)\n",
    "rf = RandomForestClassifier().fit(x_train,y_train)\n",
    "dt = DecisionTreeClassifier().fit(x_train,y_train)\n",
    "svc = SVC().fit(x_train,y_train)\n",
    "ada = AdaBoostClassifier().fit(x_train,y_train)\n",
    "gbc = GradientBoostingClassifier().fit(x_train,y_train)\n",
    "gb = xgb.XGBClassifier().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcd59e63-06c0-4f8c-9df4-c7b871b53fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "def cv_comparison(models, X, y, cv = model_selection.RepeatedStratifiedKFold(n_splits=7, n_repeats=3, random_state=1)):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    cv_accuracies = pd.DataFrame()\n",
    "\n",
    "    # Loop through the models, run a CV, add the average scores to the DataFrame and the scores of \n",
    "    # all CVs to the list\n",
    "    for model in models:\n",
    "        recalls = cross_val_score(model, x_train, y_train, scoring='recall', cv=cv)\n",
    "        recall_score = np.mean(recalls).round(2)\n",
    "        precisions = cross_val_score(model, x_train, y_train, scoring='precision', cv=cv)\n",
    "        precision_score = np.mean(precisions).round(2)\n",
    "        accuracies = cross_val_score(model, x_train,y_train, scoring='accuracy', cv=cv)\n",
    "        accuracy_score = np.mean(accuracies).round(2)\n",
    "        aucs = cross_val_score(model, x_train,y_train, scoring='roc_auc', cv=cv)\n",
    "        auc_score = np.mean(aucs).round(2)\n",
    "        f1s = cross_val_score(model, x_train,y_train, scoring='f1', cv=cv)\n",
    "        f1_score = np.mean(accuracies).round(2)\n",
    "        cv_accuracies[str(model).split('(')[0]] = [ accuracy_score, precision_score, recall_score, auc_score, f1_score]\n",
    "    cv_accuracies.index = ['Accuracy','Precision','Recall',  'AUC','F1']\n",
    "    result = cv_accuracies.transpose()\n",
    "    return result\n",
    "    # return cv_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "800973f5-f68d-47f8-ac68-3ce1400daeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression() \n",
    "RF = RandomForestClassifier()\n",
    "DT = DecisionTreeClassifier()\n",
    "SV = SVC()\n",
    "AD = AdaBoostClassifier()\n",
    "GB = GradientBoostingClassifier()\n",
    "XG = xgb.XGBClassifier()\n",
    "models = [LR,RF,DT,SV,AD,GB,XG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4712cedf-4080-4314-a9a0-55b14300adf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  Precision  Recall   AUC    F1\n",
       "LogisticRegression              0.94       0.95    0.93  0.98  0.94\n",
       "RandomForestClassifier          0.98       0.98    0.98  1.00  0.98\n",
       "DecisionTreeClassifier          0.96       0.96    0.97  0.96  0.96\n",
       "SVC                             0.96       0.96    0.96  0.99  0.96\n",
       "AdaBoostClassifier              0.94       0.95    0.94  0.99  0.94\n",
       "GradientBoostingClassifier      0.96       0.96    0.96  0.99  0.96\n",
       "XGBClassifier                   0.98       0.98    0.99  1.00  0.98"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cv_comparison(models, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac1600c1-6e34-4f1a-b374-3b3f22a322e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred_lr \u001b[38;5;241m=\u001b[39m LR\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m      2\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m      3\u001b[0m y_pred_dt \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 351\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    353\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:329\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m    Predict confidence scores for samples.\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m        this class would be predicted.\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    330\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    332\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "y_pred_lr = LR.predict(x_test)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "y_pred_dt = dt.predict(x_test)\n",
    "y_pred_svm = svc.predict(x_test)\n",
    "y_pred_ada = ada.predict(x_test)\n",
    "y_pred_gbc = gbc.predict(x_test)\n",
    "y_pred_gb = gb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05408d38-45e7-460e-be22-ae8b83e42304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmlr = metrics.confusion_matrix(y_test, y_pred_rf)\n",
    "# plt.rcParams['figure.figsize'] = (3.5, 3)\n",
    "# ax = sns.heatmap(cmlr, fmt = 'g',annot = True,cmap=\"YlGnBu\")\n",
    "# ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');  \n",
    "# ax.xaxis.set_ticklabels(['Not Purchased', 'Purchased']); ax.yaxis.set_ticklabels(['Not Purchased', 'Purchased'])\n",
    "# print (\"************************************* Confusion Matrix ******************************************\")\n",
    "# plt.show()\n",
    "\n",
    "# print (\"************************************* Classification Report *************************************\")\n",
    "# crlr = metrics.classification_report(y_test,y_pred_rf)\n",
    "# print(crlr)\n",
    "\n",
    "# print (\"************************************* description Table *****************************************\")\n",
    "# description = \"XG Boost\"  #change the name of models\n",
    "# # cmbase = cmbaselr\n",
    "\n",
    "# misclassifications = cmlr[0,1] + cmlr[1,0]         #FP + FN\n",
    "# type1 = cmlr[0,1]\n",
    "# type2 = cmlr[1,0]\n",
    "# r1 = (cmlr[1,1]  / (cmlr[1,1] + cmlr[1,0])).round(2)\n",
    "# r0 = (cmlr[0,0]  / (cmlr[0,0] + cmlr[0,1])).round(2)\n",
    "# precision = round(precision_score(y_test, y_pred_lr),2)\n",
    "# recall = round(recall_score(y_test,y_pred_lr),2)\n",
    "# accuracy = round(accuracy_score(y_test,y_pred_lr),2)\n",
    "# f1 = round(f1_score(y_test,y_pred_lr),2)\n",
    "# auc = round(roc_auc_score(y_test,y_pred_lr),2)\n",
    "# f2 = ((5 * precision * recall)/ (4 * precision + recall)).round(2)\n",
    "# df_results = pd.DataFrame(np.array([description,misclassifications,accuracy, precision, r1,r0,type1,type2,f1,f2]).reshape(1,-1)\n",
    "#                                      , columns=['Description','Misclassifications','Accuracy','Precision','Recall Minority','Recall Majority'\n",
    "#                                                 ,'Type I errors','Type II errors','F1 Score','F2 Score'])\n",
    "#                                   # ], axis=0)\n",
    "# df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
